[
  {
    "objectID": "polire/gp/tests/GP interpolation.html",
    "href": "polire/gp/tests/GP interpolation.html",
    "title": "Polire",
    "section": "",
    "text": "from pykrige import OrdinaryKriging\n\n\nimport pandas as pd\nimport numpy as np\n\n\nok = OrdinaryKriging(data[:,0],data[:,1],data[:,2])\nok.ex\n\n\na,b = ok.execute('grid',x[0],y[:,0])\n\n\nfrom pykrige import OrdinaryKriging\nimport pandas as pd\nimport numpy as np\n\ndef ordinary_kriging(dataset, resolution='standard', coordinate_type='euclidean',verbose='False',method='grid', isvariance = False):\n    if coordinate_type == 'latlong_small':\n        \"\"\"\n            Assume that the Earth is a Sphere, and use polar coordinates\n            $| \\vec{r_2}− \\vec{r_1}| ≈ \\text{R }\\times \\sqrt[]{(Lat_2 - Lat_1)^{2} + (Long_2 - Long_1)^{2}}$\n        \"\"\"\n        return \"To be done later\"\n    if coordinate_type == 'latlong_large':\n        \"\"\"\n            Code to be written after understanding all the projections.\n        \"\"\"\n        return \"To be done later\"\n    if coordinate_type==\"euclidean\":\n        \n        ok = OrdinaryKriging(dataset[:,0],dataset[:,1],dataset[:,2])\n        X = dataset[:,0]\n        y = dataset[:,1]\n        \n        if resolution=='high':\n            xx,yy = make_grid(X,y,1000)\n            \n        elif resolution=='low':\n            xx,yy = make_grid(X,y,10)\n            \n        elif resolution=='standard':\n            xx,yy = make_grid(X,y,100)\n            \n        else:\n            print('Value Error - Resolution can only be one of \\nhigh, low or standard')\n        \n        values, variances = ok.execute(method, xx[0], yy[:,0])\n        \n    if isvariance:\n        return values, variances\n    else:\n        del variances\n        return np.array(values)\n\n\nordinary_kriging(data)\n\narray([[129.94984945, 129.7682324 , 129.58820662, ..., 159.34079485,\n        159.99175016, 160.63241067],\n       [130.22090025, 130.03615966, 129.8529146 , ..., 159.9575165 ,\n        160.61228126, 161.25625641],\n       [130.50105231, 130.31324536, 130.12683652, ..., 160.59265384,\n        161.25084023, 161.8977369 ],\n       ...,\n       [207.22133238, 207.82739139, 208.44615116, ..., 248.64646661,\n        248.3790241 , 248.11033441],\n       [207.92838926, 208.53490708, 209.15376273, ..., 248.91678379,\n        248.65601627, 248.39371596],\n       [208.61942088, 209.22595474, 209.84445913, ..., 249.17442481,\n        248.9203453 , 248.66446245]])\n\n\n\nWhat does ok(‘points’) really do?\nSpecifically test when points aren’t really passed - they are let’s say the point of an array\nReturns the diagonal matrix of all these coordinates\n\n\nordinary_kriging(data,method='points')\n\narray([129.94984945, 130.03615966, 130.12683652, 130.22219703,\n       130.32258826, 130.42839089, 130.54002324, 130.65794596,\n       130.7826674 , 130.91474976, 131.05481629, 131.20355964,\n       131.36175158, 131.53025441, 131.71003442, 131.90217771,\n       132.107909  , 132.32861401, 132.56586607, 132.82145795,\n       133.0974399 , 133.39616477, 133.72034153, 134.07309736,\n       134.45804822, 134.87937482, 135.34189663, 135.85112772,\n       136.41328222, 137.03517039, 137.72388496, 138.48612122,\n       139.326921  , 140.24763047, 141.24300526, 142.29757046,\n       143.37881815, 144.38425962, 144.49187978, 143.1202101 ,\n       141.66667134, 140.45686022, 139.66795657, 142.48270308,\n       147.03665055, 151.8487008 , 156.90272514, 162.25791164,\n       168.04938768, 173.63870768, 180.93567147, 190.3440156 ,\n       199.86834472, 208.48375248, 215.75635742, 222.1915652 ,\n       228.08641413, 233.15249702, 236.89713686, 239.83524192,\n       242.45744315, 244.57483343, 245.52139699, 245.88236757,\n       246.12295211, 246.3306567 , 246.52369882, 246.70598807,\n       246.87792737, 247.03919426, 247.18952217, 247.3288843 ,\n       247.45749059, 247.57573348, 247.68412862, 247.78326467,\n       247.87376505, 247.95626051, 248.03137024, 248.09968963,\n       248.16178271, 248.21817801, 248.26936683, 248.31580309,\n       248.35790422, 248.39605277, 248.43059841, 248.46186013,\n       248.49012851, 248.51566797, 248.53871897, 248.55950011,\n       248.57821004, 248.59502931, 248.61012204, 248.62363741,\n       248.63571111, 248.64646661, 248.65601627, 248.66446245])\n\n\n\ndef make_grid(X,y,res):\n    y_min = y.min()-0.2\n    y_max = y.max()+0.2\n    x_min = X.min()-0.2\n    x_max = X.max()+0.2\n    x_arr = np.linspace(x_min,x_max,res)\n    y_arr = np.linspace(y_min,y_max,res)\n    xx,yy = np.meshgrid(x_arr,y_arr)  \n    return xx,yy\nx, y = make_grid(data[:,0],data[:,1],100)"
  },
  {
    "objectID": "polire/idw/tests/Numpy+IDWTest.html",
    "href": "polire/idw/tests/Numpy+IDWTest.html",
    "title": "Polire",
    "section": "",
    "text": "import numpy as np\n\n\na = np.array([[1,2,3],[4,5,6]])\n\n\na\n\narray([[1, 2, 3],\n       [4, 5, 6]])\n\n\n\nb = np.array([[2,3,4],[5,6,9]])\n\n\nb\n\narray([[2, 3, 4],\n       [5, 6, 9]])\n\n\n\na\n\narray([[1, 2, 3],\n       [4, 5, 6]])\n\n\n\na - b\n\narray([[-1, -1, -1],\n       [-1, -1, -3]])\n\n\n\nnp.argmin([np.linalg.norm(a[i] - b[i]) for i in range(len(a))])\n\n1.7320508075688772\n\n\n\nnp.min?\n\n\n\n\"\"\"\nThis is a module for IDW Spatial Interpolation\n\"\"\"\nimport numpy as np\nimport pandas as pd\nfrom copy import deepcopy\nclass idw():\n    \"\"\" A class that is declared for performing IDW Interpolation.\n    For more information on how this method works, kindly refer to\n    https://en.wikipedia.org/wiki/Inverse_distance_weighting\n\n    Parameters\n    ----------\n    exponent : positive float, optional\n        The rate of fall of values from source data points.\n        Higher the exponent, lower is the value when we move\n        across space. Default value is 2.\n    resolution: str, optional\n        Decides the smoothness of the interpolation. Note that\n        interpolation is done over a grid. Higher the resolution\n        means more grid cells and more time for interpolation.\n        Default value is 'standard'\n    coordinate_type: str, optional\n        Decides the distance metric to be used, while performing\n        interpolation. Euclidean by default.     \n    \"\"\"\n    def __init__(self, exponent = 2, resolution = 'standard', coordinate_type='Euclidean'):\n        \n        self.exponent = exponent\n        self.resolution = resolution\n        self.coordinate_type = coordinate_type\n        self.interpolated_values = None\n        self.x_grid = None\n        self.y_grid = None\n\n    def make_grid(self, x, y, res, offset=0.2):\n\n        \"\"\" This function returns the grid to perform interpolation on.\n           This function is used inside the fit() attribute of the idw class.\n        \n        Parameters\n        ----------\n        x: array-like, shape(n_samples,)\n            The first coordinate values of all points where\n            ground truth is available\n        y: array-like, shape(n_samples,)\n            The second coordinate values of all points where\n            ground truth is available\n        res: int\n            The resolution value\n        offset: float, optional\n            A value between 0 and 0.5 that specifies the extra interpolation to be done\n            Default is 0.2\n        \n        Returns\n        -------\n        xx : {array-like, 2D}, shape (n_samples, n_samples)\n        yy : {array-like, 2D}, shape (n_samples, n_samples)\n        \"\"\"\n        y_min = y.min() - offset\n        y_max = y.max()+ offset\n        x_min = x.min()-offset\n        x_max = x.max()+offset\n        x_arr = np.linspace(x_min,x_max,res)\n        y_arr = np.linspace(y_min,y_max,res)\n        xx,yy = np.meshgrid(x_arr,y_arr)  \n        return xx,yy\n\n    \n    def fit(self, X, y):\n        \"\"\" The function call to fit the model on the given data. \n        Parameters\n        ----------\n        X: {array-like, 2D matrix}, shape(n_samples, 2)\n            The set of all coordinates, where we have ground truth\n            values\n        y: array-like, shape(n_samples,)\n            The set of all the ground truth values using which\n            we perform interpolation\n\n        Returns\n        -------\n        self : object\n            Returns self\n        \"\"\"\n\n#          if self.coordinate_type == 'latlong_small':\n#       \"\"\"\n#           Use the conversions and projections for small changes in LatLong\n#       \"\"\"\n#           print (\"To be done later\")\n#             return self\n\n#         if self.coordinate_type == 'latlong_large':\n#             \"\"\"\n#                 Code to be written after understanding all the projections.\n#             \"\"\"\n#             print (\"To be done later\")\n#             return self\n\n        if self.coordinate_type==\"Euclidean\":\n            \n            X = deepcopy(np.c_[X,y])\n\n            if self.resolution=='high':\n                xx,yy = self.make_grid(X,y,1000)\n                \n            if self.resolution=='low':\n                xx,yy = self.make_grid(X,y,10)\n                \n            if self.resolution=='standard':\n                xx,yy = self.make_grid(X,y,100)\n\n            new = []\n            new_arr = deepcopy(X)\n            for points in new_arr:\n                min_dist = np.inf\n                val = 0\n                for j in range(len(yy)):\n                    temp = yy[j][0]\n                    for i in range(len(xx[0])):\n                        dist = np.linalg.norm(np.array([xx[0][i],temp]) - points[:2])\n                        if dist&lt;min_dist:\n                            min_dist = dist\n                            val = (i,j)\n                new.append((points,val))\n            new_grid = np.zeros((len(xx),len(yy)))\n            for i in range(len(new)):\n                x = new[i][1][0]\n                y = new[i][1][1]\n                new_grid[x][y] = new[i][0][2]\n            x_nz,y_nz = np.nonzero(new_grid)\n            list_nz = []\n            for i in range(len(x_nz)):\n                list_nz.append((x_nz[i],y_nz[i]))\n            final = np.copy(new_grid)\n            for i in range(len(xx[0])):\n                for j in range(len(yy)):\n                    normalise = 0\n                    if (i,j) in list_nz:\n                        continue\n                    else:\n                        for elem in range(len(x_nz)):\n                            source = np.array([x_nz[elem],y_nz[elem]])\n                            target = np.array([xx[0][i],yy[j][0]])\n                            dist = (np.abs(xx[0][source[0]] - target[0])**self.exponent + np.abs(yy[source[1]][0] - target[1])**self.exponent)**(1/self.exponent)\n                            final[i][j]+=new_grid[x_nz[elem],y_nz[elem]]/dist\n                            normalise+=1/(dist)\n                    final[i][j]/=normalise\n            self.interpolated_values = final\n            self.x_grid = xx\n            self.y_grid = yy\n        \n        return self\n\n#     def predict(self, X):\n#         \"\"\" The function call to predict using the interpolated data\n#         Parameters\n#         ----------\n#         X: {array-like, 2D matrix}, shape(n_samples, 2)\n#             The set of all coordinates, where we have ground truth\n#             values\n        \n\n#         Returns\n#         -------\n#         y: array-like, shape(n_samples,)\n#             The set of all the ground truth values using which\n#             we perform interpolation \n#         \"\"\"\n#         if self.coordinate_type == 'Euclidean':\n#             for i in range(self.x_grid[0]):\n#                 for j in range()\n        \n#         else:\n#             print(\"Will be done later\")\n#             return \n            \n                \n# self.x_grid\n\n\n\na = idw()\nimport pandas as pd\ndf = pd.read_csv('../../testdata/30-03-18.csv')\ndata = np.array(df[['longitude','latitude','value']])\na.fit(data[:,:2],data[:,2])\n\n&lt;__main__.idw at 0x7f36db6f9c88&gt;\n\n\n\na.interpolated_values\n\narray([[171.89189189, 171.89597641, 171.90813547, ..., 173.89050472,\n        173.89261459, 173.89466512],\n       [171.77142857, 171.77625338, 171.79060316, ..., 173.89585441,\n        173.89787202, 173.89983245],\n       [171.63636364, 171.64211895, 171.65921778, ..., 173.9012935 ,\n        173.90321551, 173.90508269],\n       ...,\n       [174.49681529, 174.49676176, 174.49660126, ..., 174.24671184,\n        174.24416446, 174.24164382],\n       [174.49056604, 174.49051451, 174.49035999, ..., 174.24671343,\n        174.24419773, 174.2417078 ],\n       [174.48447205, 174.48442242, 174.48427358, ..., 174.2466762 ,\n        174.24419219, 174.24173298]])"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Polire",
    "section": "",
    "text": "pip install polire\nThe word “interpolation” has Latin origin and is composed of two words - Inter meaning between and Polire meaning to polish.\nPolire is a collection of several spatial interpolation algorithms."
  },
  {
    "objectID": "index.html#polire",
    "href": "index.html#polire",
    "title": "Polire",
    "section": "",
    "text": "pip install polire\nThe word “interpolation” has Latin origin and is composed of two words - Inter meaning between and Polire meaning to polish.\nPolire is a collection of several spatial interpolation algorithms."
  },
  {
    "objectID": "examples/all_in_one.html",
    "href": "examples/all_in_one.html",
    "title": "Basic Example",
    "section": "",
    "text": "In this notebook, we will see how to use Polire for spatial interpolation.\nimport numpy as np\nimport xarray as xr\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport polire\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\n\nfrom sklearn.metrics import (\n    mean_squared_error,\n    mean_absolute_error,\n    mean_absolute_percentage_error,\n    r2_score,\n)\n\n# set default cmap\nplt.rcParams[\"image.cmap\"] = \"RdYlGn_r\"\nxr.set_options(cmap_sequential=\"RdYlGn_r\")\n\n&lt;xarray.core.options.set_options at 0x7fc3b0198c40&gt;"
  },
  {
    "objectID": "examples/all_in_one.html#load-the-data",
    "href": "examples/all_in_one.html#load-the-data",
    "title": "Basic Example",
    "section": "Load the data",
    "text": "Load the data\n\nds = xr.tutorial.open_dataset(\"air_temperature\")\nds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:  (lat: 25, time: 2920, lon: 53)\nCoordinates:\n  * lat      (lat) float32 75.0 72.5 70.0 67.5 65.0 ... 25.0 22.5 20.0 17.5 15.0\n  * lon      (lon) float32 200.0 202.5 205.0 207.5 ... 322.5 325.0 327.5 330.0\n  * time     (time) datetime64[ns] 2013-01-01 ... 2014-12-31T18:00:00\nData variables:\n    air      (time, lat, lon) float32 ...\nAttributes:\n    Conventions:  COARDS\n    title:        4x daily NMC reanalysis (1948)\n    description:  Data is from NMC initialized reanalysis\\n(4x/day).  These a...\n    platform:     Model\n    references:   http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reanaly...xarray.DatasetDimensions:lat: 25time: 2920lon: 53Coordinates: (3)lat(lat)float3275.0 72.5 70.0 ... 20.0 17.5 15.0standard_name :latitudelong_name :Latitudeunits :degrees_northaxis :Yarray([75. , 72.5, 70. , 67.5, 65. , 62.5, 60. , 57.5, 55. , 52.5, 50. , 47.5,\n       45. , 42.5, 40. , 37.5, 35. , 32.5, 30. , 27.5, 25. , 22.5, 20. , 17.5,\n       15. ], dtype=float32)lon(lon)float32200.0 202.5 205.0 ... 327.5 330.0standard_name :longitudelong_name :Longitudeunits :degrees_eastaxis :Xarray([200. , 202.5, 205. , 207.5, 210. , 212.5, 215. , 217.5, 220. , 222.5,\n       225. , 227.5, 230. , 232.5, 235. , 237.5, 240. , 242.5, 245. , 247.5,\n       250. , 252.5, 255. , 257.5, 260. , 262.5, 265. , 267.5, 270. , 272.5,\n       275. , 277.5, 280. , 282.5, 285. , 287.5, 290. , 292.5, 295. , 297.5,\n       300. , 302.5, 305. , 307.5, 310. , 312.5, 315. , 317.5, 320. , 322.5,\n       325. , 327.5, 330. ], dtype=float32)time(time)datetime64[ns]2013-01-01 ... 2014-12-31T18:00:00standard_name :timelong_name :Timearray(['2013-01-01T00:00:00.000000000', '2013-01-01T06:00:00.000000000',\n       '2013-01-01T12:00:00.000000000', ..., '2014-12-31T06:00:00.000000000',\n       '2014-12-31T12:00:00.000000000', '2014-12-31T18:00:00.000000000'],\n      dtype='datetime64[ns]')Data variables: (1)air(time, lat, lon)float32...long_name :4xDaily Air temperature at sigma level 995units :degKprecision :2GRIB_id :11GRIB_name :TMPvar_desc :Air temperaturedataset :NMC Reanalysislevel_desc :Surfacestatistic :Individual Obsparent_stat :Otheractual_range :[185.16 322.1 ][3869000 values with dtype=float32]Indexes: (3)latPandasIndexPandasIndex(Index([75.0, 72.5, 70.0, 67.5, 65.0, 62.5, 60.0, 57.5, 55.0, 52.5, 50.0, 47.5,\n       45.0, 42.5, 40.0, 37.5, 35.0, 32.5, 30.0, 27.5, 25.0, 22.5, 20.0, 17.5,\n       15.0],\n      dtype='float32', name='lat'))lonPandasIndexPandasIndex(Index([200.0, 202.5, 205.0, 207.5, 210.0, 212.5, 215.0, 217.5, 220.0, 222.5,\n       225.0, 227.5, 230.0, 232.5, 235.0, 237.5, 240.0, 242.5, 245.0, 247.5,\n       250.0, 252.5, 255.0, 257.5, 260.0, 262.5, 265.0, 267.5, 270.0, 272.5,\n       275.0, 277.5, 280.0, 282.5, 285.0, 287.5, 290.0, 292.5, 295.0, 297.5,\n       300.0, 302.5, 305.0, 307.5, 310.0, 312.5, 315.0, 317.5, 320.0, 322.5,\n       325.0, 327.5, 330.0],\n      dtype='float32', name='lon'))timePandasIndexPandasIndex(DatetimeIndex(['2013-01-01 00:00:00', '2013-01-01 06:00:00',\n               '2013-01-01 12:00:00', '2013-01-01 18:00:00',\n               '2013-01-02 00:00:00', '2013-01-02 06:00:00',\n               '2013-01-02 12:00:00', '2013-01-02 18:00:00',\n               '2013-01-03 00:00:00', '2013-01-03 06:00:00',\n               ...\n               '2014-12-29 12:00:00', '2014-12-29 18:00:00',\n               '2014-12-30 00:00:00', '2014-12-30 06:00:00',\n               '2014-12-30 12:00:00', '2014-12-30 18:00:00',\n               '2014-12-31 00:00:00', '2014-12-31 06:00:00',\n               '2014-12-31 12:00:00', '2014-12-31 18:00:00'],\n              dtype='datetime64[ns]', name='time', length=2920, freq=None))Attributes: (5)Conventions :COARDStitle :4x daily NMC reanalysis (1948)description :Data is from NMC initialized reanalysis\n(4x/day).  These are the 0.9950 sigma level values.platform :Modelreferences :http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reanalysis.html\n\n\nLet’s visualize the spatial data from a time-stamp.\n\nds_spatial = ds.isel(time=0)\nds_spatial[\"air\"].plot()\nplt.show()\n\n\n\n\nLet’s assume that only 10% of the data is available and try to interpolate the rest of the data.\n\nds_spatial_train = ds_spatial.copy()\n\nnp.random.seed(42)\nds_spatial_train[\"air\"].values = np.where(\n    np.random.rand(*ds_spatial_train[\"air\"].shape) &gt; 0.1,\n    np.nan,\n    ds_spatial_train[\"air\"].values,\n)\n\n\nds_spatial_train[\"air\"].plot()\nplt.show()"
  },
  {
    "objectID": "examples/all_in_one.html#prepare-the-data",
    "href": "examples/all_in_one.html#prepare-the-data",
    "title": "Basic Example",
    "section": "Prepare the data",
    "text": "Prepare the data\n\ntrain_df = ds_spatial_train[\"air\"].to_dataframe().reset_index()\ntrain_df = train_df.dropna()\n\nX_train = train_df[[\"lat\", \"lon\"]].values\ny_train = train_df[\"air\"].values\n\ntest_df = ds_spatial[\"air\"].to_dataframe().reset_index()\nX_test = test_df[[\"lat\", \"lon\"]].values\ny_test = test_df[\"air\"].values\n\nprint(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n\n(146, 2) (146,) (1325, 2) (1325,)"
  },
  {
    "objectID": "examples/all_in_one.html#useful-plotting-function",
    "href": "examples/all_in_one.html#useful-plotting-function",
    "title": "Basic Example",
    "section": "Useful plotting function",
    "text": "Useful plotting function\n\ndef plot_predictions(y_pred, model_name):\n    fig, axes = plt.subplots(\n        1, 3, figsize=(15, 4), gridspec_kw={\"width_ratios\": [1, 1, 0.05]}\n    )\n\n    ax = axes[0]\n    ds_spatial[\"air\"].plot(ax=ax, add_colorbar=False)\n    ax.set_title(\"True values\")\n\n    ax = axes[1]\n    ds_spatial_pred = ds_spatial_train.copy()\n    ds_spatial_pred[\"air\"].values = y_pred\n    mappable = ds_spatial_pred[\"air\"].plot(ax=ax, add_colorbar=False)\n    ax.set_title(f\"{model_name}\")\n\n    ax = axes[2]\n    fig.colorbar(mappable, cax=ax)"
  },
  {
    "objectID": "examples/all_in_one.html#models",
    "href": "examples/all_in_one.html#models",
    "title": "Basic Example",
    "section": "Models",
    "text": "Models\n\nIDW\n\nidw = polire.IDW(exponent=2)\nidw.fit(X_train, y_train)\nidw_pred = idw.predict(X_test).reshape(ds_spatial[\"air\"].shape)\n\nplot_predictions(idw_pred, \"IDW\")\n\n/home/patel_zeel/polire/polire/idw/idw.py:82: RuntimeWarning: divide by zero encountered in divide\n  weights = 1 / np.power(dist, self.exponent)\n/home/patel_zeel/polire/polire/idw/idw.py:83: RuntimeWarning: invalid value encountered in divide\n  result = (weights * self.y[:, None]).sum(axis=0) / weights.sum(axis=0)\n\n\n\n\n\n\n\nKriging\n\nkriging = polire.Kriging(variogram_model=\"spherical\")\nkriging.fit(X_train, y_train)\nkriging_pred = kriging.predict(X_test).reshape(ds_spatial[\"air\"].shape)\n\nplot_predictions(kriging_pred, \"Kriging\")\n\n\n\n\n\n\nSpline\n\nspline = polire.Spline()\nspline.fit(X_train, y_train)\nspline_pred = spline.predict(X_test).reshape(ds_spatial[\"air\"].shape)\n\nplot_predictions(spline_pred, \"Spline\")\n\n/home/patel_zeel/miniconda3/envs/polire/lib/python3.10/site-packages/scipy/interpolate/_fitpack_impl.py:593: RuntimeWarning: The required storage space exceeds the available storage space.\nProbable causes: nxest or nyest too small or s is too small. (fp&gt;s)\n    kx,ky=3,3 nx,ny=11,11 m=146 fp=1143.783495 s=128.911993\n  warnings.warn(RuntimeWarning(_iermess2[ierm][0] + _mess))\n\n\n\n\n\n\n\nTrend\n\ntrend = polire.Trend(order=2)\ntrend.fit(X_train, y_train)\ntrend_pred = trend.predict(X_test).reshape(ds_spatial[\"air\"].shape)\n\nplot_predictions(trend_pred, \"Trend\")\n\n\n\n\n\n\nSpatialAverage\n\nspatial_average = polire.SpatialAverage(radius=15)\nspatial_average.fit(X_train, y_train)\nspatial_average_pred = spatial_average.predict(X_test).reshape(ds_spatial[\"air\"].shape)\n\nplot_predictions(spatial_average_pred, \"SpatialAverage\")\n\n\n\n\n\n\nLinearRegression\n\nlr = polire.CustomInterpolator(LinearRegression())\nlr.fit(X_train, y_train)\nlr_pred = lr.predict(X_test).reshape(ds_spatial[\"air\"].shape)\n\nplot_predictions(lr_pred, \"Linear Regression\")\n\n\n\n\n\n\nNearestNeighbors\n\nK = 3\nknn = polire.CustomInterpolator(KNeighborsRegressor(n_neighbors=K))\nknn.fit(X_train, y_train)\nknn_pred = knn.predict(X_test).reshape(ds_spatial[\"air\"].shape)\n\nplot_predictions(knn_pred, \"KNN\")\n\n\n\n\n\n\nRandom Forest\n\nrf = polire.CustomInterpolator(RandomForestRegressor(random_state=42))\nrf.fit(X_train, y_train)\nrf_pred = rf.predict(X_test).reshape(ds_spatial[\"air\"].shape)\n\nplot_predictions(rf_pred, \"Random Forest\")"
  },
  {
    "objectID": "examples/all_in_one.html#checking-performance",
    "href": "examples/all_in_one.html#checking-performance",
    "title": "Basic Example",
    "section": "Checking performance",
    "text": "Checking performance\n\nmodels = {\n    \"Inverse Distance Weighting\": idw_pred,\n    \"Kriging (spherical)\": kriging_pred,\n    \"Spline\": spline_pred,\n    \"Trend\": trend_pred,\n    \"Linear Regression\": lr_pred,\n    f\"{K}-Nearest Neighbors\": knn_pred,\n    \"Random Forest\": rf_pred,\n    \"Spatial Average\": spatial_average_pred,\n}\n\nresult = pd.DataFrame(columns=[\"RMSE\", \"MAE\", \"MAPE\", \"Neg R2\"], index=models.keys())\n\nfor model_name, y_pred in models.items():\n    result.loc[model_name, \"RMSE\"] = mean_squared_error(\n        y_test.ravel(), y_pred.ravel(), squared=False\n    )\n    result.loc[model_name, \"MAE\"] = mean_absolute_error(y_test.ravel(), y_pred.ravel())\n    result.loc[model_name, \"MAPE\"] = mean_absolute_percentage_error(\n        y_test.ravel(), y_pred.ravel()\n    )\n    result.loc[model_name, \"Neg R2\"] = -r2_score(y_test.ravel(), y_pred.ravel())\n\nresult.sort_values(\"RMSE\").style.highlight_min(axis=0, color=\"green\").format(\"{:.2f}\")\n\n\n\n\n\n\n \nRMSE\nMAE\nMAPE\nNeg R2\n\n\n\n\nKriging (spherical)\n3.10\n1.95\n0.01\n-0.97\n\n\nRandom Forest\n3.96\n2.74\n0.01\n-0.96\n\n\nSpline\n4.43\n2.85\n0.01\n-0.95\n\n\n3-Nearest Neighbors\n4.60\n3.19\n0.01\n-0.94\n\n\nSpatial Average\n6.04\n4.32\n0.02\n-0.90\n\n\nInverse Distance Weighting\n6.54\n5.04\n0.02\n-0.88\n\n\nTrend\n8.02\n6.30\n0.02\n-0.82\n\n\nLinear Regression\n8.46\n6.98\n0.03\n-0.80"
  },
  {
    "objectID": "polire/kriging/tests/Kriging Interpolation.html",
    "href": "polire/kriging/tests/Kriging Interpolation.html",
    "title": "Polire",
    "section": "",
    "text": "from pykrige import OrdinaryKriging\n\n\nimport pandas as pd\nimport numpy as np\n\n\nok = OrdinaryKriging(data[:,0],data[:,1],data[:,2])\nok.ex\n\n\na,b = ok.execute('grid',x[0],y[:,0])\n\n\nfrom pykrige import OrdinaryKriging\nimport pandas as pd\nimport numpy as np\n\ndef ordinary_kriging(dataset, resolution='standard', coordinate_type='euclidean',verbose='False',method='grid', isvariance = False):\n    if coordinate_type == 'latlong_small':\n        \"\"\"\n            Assume that the Earth is a Sphere, and use polar coordinates\n            $| \\vec{r_2}− \\vec{r_1}| ≈ \\text{R }\\times \\sqrt[]{(Lat_2 - Lat_1)^{2} + (Long_2 - Long_1)^{2}}$\n        \"\"\"\n        return \"To be done later\"\n    if coordinate_type == 'latlong_large':\n        \"\"\"\n            Code to be written after understanding all the projections.\n        \"\"\"\n        return \"To be done later\"\n    if coordinate_type==\"euclidean\":\n        \n        ok = OrdinaryKriging(dataset[:,0],dataset[:,1],dataset[:,2])\n        X = dataset[:,0]\n        y = dataset[:,1]\n        \n        if resolution=='high':\n            xx,yy = make_grid(X,y,1000)\n            \n        elif resolution=='low':\n            xx,yy = make_grid(X,y,10)\n            \n        elif resolution=='standard':\n            xx,yy = make_grid(X,y,100)\n            \n        else:\n            print('Value Error - Resolution can only be one of \\nhigh, low or standard')\n        \n        values, variances = ok.execute(method, xx[0], yy[:,0])\n        \n    if isvariance:\n        return values, variances\n    else:\n        del variances\n        return np.array(values)\n\n\nordinary_kriging(data)\n\narray([[129.94984945, 129.7682324 , 129.58820662, ..., 159.34079485,\n        159.99175016, 160.63241067],\n       [130.22090025, 130.03615966, 129.8529146 , ..., 159.9575165 ,\n        160.61228126, 161.25625641],\n       [130.50105231, 130.31324536, 130.12683652, ..., 160.59265384,\n        161.25084023, 161.8977369 ],\n       ...,\n       [207.22133238, 207.82739139, 208.44615116, ..., 248.64646661,\n        248.3790241 , 248.11033441],\n       [207.92838926, 208.53490708, 209.15376273, ..., 248.91678379,\n        248.65601627, 248.39371596],\n       [208.61942088, 209.22595474, 209.84445913, ..., 249.17442481,\n        248.9203453 , 248.66446245]])\n\n\n\nWhat does ok(‘points’) really do?\nSpecifically test when points aren’t really passed - they are let’s say the point of an array\nReturns the diagonal matrix of all these coordinates\n\n\nordinary_kriging(data,method='points')\n\narray([129.94984945, 130.03615966, 130.12683652, 130.22219703,\n       130.32258826, 130.42839089, 130.54002324, 130.65794596,\n       130.7826674 , 130.91474976, 131.05481629, 131.20355964,\n       131.36175158, 131.53025441, 131.71003442, 131.90217771,\n       132.107909  , 132.32861401, 132.56586607, 132.82145795,\n       133.0974399 , 133.39616477, 133.72034153, 134.07309736,\n       134.45804822, 134.87937482, 135.34189663, 135.85112772,\n       136.41328222, 137.03517039, 137.72388496, 138.48612122,\n       139.326921  , 140.24763047, 141.24300526, 142.29757046,\n       143.37881815, 144.38425962, 144.49187978, 143.1202101 ,\n       141.66667134, 140.45686022, 139.66795657, 142.48270308,\n       147.03665055, 151.8487008 , 156.90272514, 162.25791164,\n       168.04938768, 173.63870768, 180.93567147, 190.3440156 ,\n       199.86834472, 208.48375248, 215.75635742, 222.1915652 ,\n       228.08641413, 233.15249702, 236.89713686, 239.83524192,\n       242.45744315, 244.57483343, 245.52139699, 245.88236757,\n       246.12295211, 246.3306567 , 246.52369882, 246.70598807,\n       246.87792737, 247.03919426, 247.18952217, 247.3288843 ,\n       247.45749059, 247.57573348, 247.68412862, 247.78326467,\n       247.87376505, 247.95626051, 248.03137024, 248.09968963,\n       248.16178271, 248.21817801, 248.26936683, 248.31580309,\n       248.35790422, 248.39605277, 248.43059841, 248.46186013,\n       248.49012851, 248.51566797, 248.53871897, 248.55950011,\n       248.57821004, 248.59502931, 248.61012204, 248.62363741,\n       248.63571111, 248.64646661, 248.65601627, 248.66446245])\n\n\n\ndef make_grid(X,y,res):\n    y_min = y.min()-0.2\n    y_max = y.max()+0.2\n    x_min = X.min()-0.2\n    x_max = X.max()+0.2\n    x_arr = np.linspace(x_min,x_max,res)\n    y_arr = np.linspace(y_min,y_max,res)\n    xx,yy = np.meshgrid(x_arr,y_arr)  \n    return xx,yy\nx, y = make_grid(data[:,0],data[:,1],100)"
  },
  {
    "objectID": "polire/idw/tests/IDW Initial.html",
    "href": "polire/idw/tests/IDW Initial.html",
    "title": "Inverse Distance Weighting (IDW) Interpolation",
    "section": "",
    "text": "Let us suppose we have a data that shows the variation of one quantity of interest across space. This could be equivalently viewed as { (\\(\\vec{x_1}, y_1)\\),\\((\\vec{x_2}, y_2)\\),\\((\\vec{x_3}, y_3)\\), …}, where the \\(\\vec{x_i}\\)’s represent the coordinates of the points where we have data and the \\(y_i\\)’s are the actual data at those points.  We would like to perform an interpolation using these data points such that a few things are satisifed. 1. The interpolation is exact - the value at the known data points is the same as the estimated value, and 2. We would want far away points from a given source data point to receive less importance than nearby points. 3. Wikipedia has an excellent article on IDW. I am linking it here.\nWe are using the following approximation for coordinate_type being latlong_small \\(| \\vec{r_2}− \\vec{r_1}| ≈ \\text{R }\\times \\sqrt[]{(Lat_2 - Lat_1)^{2} + (Long_2 - Long_1)^{2}}\\)\n\nimport numpy as np\nimport pandas as pd\ndf = pd.read_csv('../../testdata/30-03-18.csv')\ndata = np.array(df[['longitude','latitude','value']])\n\n\ndef make_grid(X,y,res):\n    y_min = y.min()-0.2\n    y_max = y.max()+0.2\n    x_min = X.min()-0.2\n    x_max = X.max()+0.2\n    x_arr = np.linspace(x_min,x_max,res)\n    y_arr = np.linspace(y_min,y_max,res)\n    xx,yy = np.meshgrid(x_arr,y_arr)  \n    return xx,yy\n\ndef idw(dataset, exponent = 2,  resolution='standard', coordinate_type='euclidean',verbose='False'):\n    \"\"\"\n        Here X is the set of spatial locations - Usually assumed to be Lat-Long\n        To be extended to higher dimenstions y - estimated value , exponenet - how\n        much weight to assign to far off locations to be estimated for each data point, \n        extent - interpolate over a grid - what is xmax xmin ymax ymin\n    \"\"\"\n    if coordinate_type == 'latlong_small':\n        \"\"\"\n            Assume that the Earth is a Sphere, and use polar coordinates\n            $| \\vec{r_2}− \\vec{r_1}| ≈ \\text{R }\\times \\sqrt[]{(Lat_2 - Lat_1)^{2} + (Long_2 - Long_1)^{2}}$\n        \"\"\"\n        return \"To be done later\"\n    if coordinate_type == 'latlong_large':\n        \"\"\"\n            Code to be written after understanding all the projections.\n        \"\"\"\n        return \"To be done later\"\n    if coordinate_type==\"euclidean\":\n        \n#         print(dataset)\n        X = dataset[:,0]\n        y = dataset[:,1]\n        if resolution=='high':\n            xx,yy = make_grid(X,y,1000)\n            \n        if resolution=='low':\n            xx,yy = make_grid(X,y,10)\n            \n        if resolution=='standard':\n            xx,yy = make_grid(X,y,100)\n        \n        new = []\n        new_arr = dataset\n        for points in new_arr:\n            mindist = np.inf\n            val = 0\n            for j in range(len(yy)):\n                temp = yy[j][0]\n                for i in range(len(xx[0])):\n                    dist = np.linalg.norm(np.array([xx[0][i],temp]) - points[:2])\n                    if dist&lt;mindist:\n                        mindist = dist\n                        val = (i,j)\n            new.append((points,val))\n        print(new)\n        new_grid = np.zeros((len(xx),len(yy)))\n        for i in range(len(new)):\n            x = new[i][1][0]\n            y = new[i][1][1]\n            new_grid[x][y] = new[i][0][2]\n            print(new[i])\n        x_nz,y_nz = np.nonzero(new_grid)\n        list_nz = []\n        for i in range(len(x_nz)):\n            list_nz.append((x_nz[i],y_nz[i]))\n        \n        final = np.copy(new_grid)\n        \n        for i in range(len(xx[0])):\n            for j in range(len(yy)):\n                normalise = 0\n                if (i,j) in list_nz:\n                    continue\n                else:\n                    \"\"\"\n                    Could potentially have a divide by zero error here\n                    Use a try except clause\n                    \"\"\"\n                    for elem in range(len(x_nz)):\n                        source = np.array([x_nz[elem],y_nz[elem]])\n                        target = np.array([xx[0][i],yy[j][0]])\n                        dist = (np.abs(xx[0][source[0]] - target[0])**exponent + np.abs(yy[source[1]][0] - target[1])**exponent)**(1/exponent)\n                        final[i][j]+=new_grid[x_nz[elem],y_nz[elem]]/dist\n                        normalise+=1/(dist)\n                final[i][j]/=normalise\n    \n    return final\n\n\nidw(data).shape\n\n[(array([ 77.234291,  28.581197, 194.      ]), (60, 39)), (array([ 77.245721,  28.739434, 267.      ]), (62, 60)), (array([ 77.101961,  28.822931, 273.      ]), (42, 72)), (array([ 76.991463,  28.620806, 129.      ]), (27, 44)), (array([ 77.0325413,  28.60909  , 176.       ]), (33, 42)), (array([ 77.072196,  28.570859, 172.      ]), (38, 37)), (array([ 77.1670103,  28.5646102, 168.       ]), (51, 36)), (array([ 77.1180053,  28.5627763, 105.       ]), (45, 36)), (array([ 77.272404,  28.530782, 203.      ]), (66, 32)), (array([ 77.26075 ,  28.563827, 192.      ]), (64, 36)), (array([77.0996943, 28.610304 , 95.       ]), (42, 43)), (array([ 77.2273074,  28.5918245, 148.       ]), (59, 40)), (array([ 77.09211 ,  28.732219, 203.      ]), (41, 59)), (array([ 77.317084,  28.668672, 221.      ]), (72, 51)), (array([ 77.1585447,  28.6573814, 141.       ]), (50, 49)), (array([ 77.2011573,  28.6802747, 192.       ]), (56, 52)), (array([ 77.237372,  28.612561, 203.      ]), (61, 43)), (array([ 77.305651,  28.632707, 152.      ]), (70, 46)), (array([ 77.1473105,  28.6514781, 185.       ]), (49, 48)), (array([ 77.16482 ,  28.699254, 290.      ]), (51, 55)), (array([ 77.170221,  28.728722, 273.      ]), (52, 59)), (array([ 77.2005604,  28.6372688, 173.       ]), (56, 46)), (array([ 77.2011573,  28.7256504, 269.       ]), (56, 58)), (array([ 77.136777,  28.669119, 160.      ]), (47, 51)), (array([77.267246, 28.49968 , 78.      ]), (65, 27)), (array([ 77.2494387,  28.6316945, 211.       ]), (62, 45)), (array([ 77.2735737,  28.5512005, 252.       ]), (66, 34)), (array([ 77.2159377,  28.5504249, 133.       ]), (58, 34)), (array([77.1112615, 28.7500499, 77.       ]), (44, 62)), (array([77.22445, 28.63576, 96.     ]), (59, 46))]\n(array([ 77.234291,  28.581197, 194.      ]), (60, 39))\n(array([ 77.245721,  28.739434, 267.      ]), (62, 60))\n(array([ 77.101961,  28.822931, 273.      ]), (42, 72))\n(array([ 76.991463,  28.620806, 129.      ]), (27, 44))\n(array([ 77.0325413,  28.60909  , 176.       ]), (33, 42))\n(array([ 77.072196,  28.570859, 172.      ]), (38, 37))\n(array([ 77.1670103,  28.5646102, 168.       ]), (51, 36))\n(array([ 77.1180053,  28.5627763, 105.       ]), (45, 36))\n(array([ 77.272404,  28.530782, 203.      ]), (66, 32))\n(array([ 77.26075 ,  28.563827, 192.      ]), (64, 36))\n(array([77.0996943, 28.610304 , 95.       ]), (42, 43))\n(array([ 77.2273074,  28.5918245, 148.       ]), (59, 40))\n(array([ 77.09211 ,  28.732219, 203.      ]), (41, 59))\n(array([ 77.317084,  28.668672, 221.      ]), (72, 51))\n(array([ 77.1585447,  28.6573814, 141.       ]), (50, 49))\n(array([ 77.2011573,  28.6802747, 192.       ]), (56, 52))\n(array([ 77.237372,  28.612561, 203.      ]), (61, 43))\n(array([ 77.305651,  28.632707, 152.      ]), (70, 46))\n(array([ 77.1473105,  28.6514781, 185.       ]), (49, 48))\n(array([ 77.16482 ,  28.699254, 290.      ]), (51, 55))\n(array([ 77.170221,  28.728722, 273.      ]), (52, 59))\n(array([ 77.2005604,  28.6372688, 173.       ]), (56, 46))\n(array([ 77.2011573,  28.7256504, 269.       ]), (56, 58))\n(array([ 77.136777,  28.669119, 160.      ]), (47, 51))\n(array([77.267246, 28.49968 , 78.      ]), (65, 27))\n(array([ 77.2494387,  28.6316945, 211.       ]), (62, 45))\n(array([ 77.2735737,  28.5512005, 252.       ]), (66, 34))\n(array([ 77.2159377,  28.5504249, 133.       ]), (58, 34))\n(array([77.1112615, 28.7500499, 77.       ]), (44, 62))\n(array([77.22445, 28.63576, 96.     ]), (59, 46))\n\n\n(100, 100)\n\n\n\ntemp = data[10]\n\n\nnp.where(data==temp)\n\n(array([10, 10, 10]), array([0, 1, 2]))\n\n\n\nresult  = np.nonzero(data==temp)\n\n\nnp.unique(result[0])[0]\n\n10\n\n\n\nlistOfCoordinates= list(zip(result[0], result[1]))\n\n\nlistOfCoordinates\n\n[(10, 0), (10, 1), (10, 2)]"
  }
]